{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmD9CdaO9Jn+dwHurxR73g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kashishsingla111/Samplingsub2/blob/main/Sampling2_K50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LXtRp3lISpzv"
      },
      "outputs": [],
      "source": [
        "#Let's import the required libraries first\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler, NearMiss, TomekLinks\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset load\n",
        "datacr = pd.read_csv(\"/content/Creditcard_data.csv\")"
      ],
      "metadata": {
        "id": "coT-xxfmT0Kl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#before balancing\n",
        "print(\"Class distribution before balancing:\")\n",
        "print(datacr['Class'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6XSxvjuT0M6",
        "outputId": "0affc25c-a1bf-4bd0-bc8f-76a6513c0e21"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution before balancing:\n",
            "0    763\n",
            "1      9\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#features and target variable\n",
        "X = datacr.drop('Class', axis=1)\n",
        "y = datacr['Class']"
      ],
      "metadata": {
        "id": "Mzj3TJzvT0QV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Balancing with RandomOverSampler as we don't have ton of data to work with.\n",
        "rover = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = rover.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "yIRE_6T3UNwd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#after sampling\n",
        "print(\"Class distribution after balancing:\")\n",
        "print(pd.Series(y_resampled).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6EzDYKeUNzz",
        "outputId": "d8e29147-7c75-45d7-cf81-b8932e09d7c1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution after balancing:\n",
            "0    763\n",
            "1    763\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating five samples\n",
        "sizeofsample = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "samples = []"
      ],
      "metadata": {
        "id": "6QkRpGbrU1KB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for size in sizeofsample:\n",
        "    X_sample, _, y_sample, _ = train_test_split(X_resampled, y_resampled, test_size=size, random_state=42)\n",
        "    samples.append((X_sample, y_sample))"
      ],
      "metadata": {
        "id": "pj5oH31HU1Lv"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#five ML models used\n",
        "models = [RandomForestClassifier(random_state=42),\n",
        "          SVC(random_state=42),\n",
        "          LogisticRegression(random_state=42),\n",
        "          KNeighborsClassifier(),\n",
        "          DecisionTreeClassifier(random_state=42)]"
      ],
      "metadata": {
        "id": "xcbnmezaU1PM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#five sampling techniques used\n",
        "sampling_techniques = [RandomOverSampler(random_state=42),\n",
        "                       SMOTE(random_state=42),\n",
        "                       NearMiss(version=1, n_neighbors=3),\n",
        "                       TomekLinks(),\n",
        "                       RandomUnderSampler(random_state=42)]"
      ],
      "metadata": {
        "id": "MSvzgj-oVE47"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "    row_results = []\n",
        "    for j, technique in enumerate(sampling_techniques):\n",
        "\n",
        "        X_resampled, y_resampled = technique.fit_resample(samples[j][0], samples[j][1])\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)*100\n",
        "        row_results.append(accuracy)\n",
        "\n",
        "    results.append(row_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c12eOLSNVE7b",
        "outputId": "2a058cac-bf21-41ee-d062-37829ccaefed"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the results in a dataframe(easy to read)\n",
        "result_df = pd.DataFrame(results, columns=[\"Sampling1\", \"Sampling2\", \"Sampling3\", \"Sampling4\", \"Sampling5\"],\n",
        "                         index=[\"M1\", \"M2\", \"M3\", \"M4\", \"M5\"])\n"
      ],
      "metadata": {
        "id": "tNyAbeB1VE_E"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "M1= RandomForest, M2= SVC, M3= Logistic Regression, M4= K Neighbours, M5= DecisionTree\n",
        "S1= RandomOverSampler, S2= SMOTE, S3= NearMiss, S3= TomekLinks, S5= RandomUnderSampler"
      ],
      "metadata": {
        "id": "-Tlheu3UYEQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy results:\")\n",
        "print(result_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MqVkmbIVpkQ",
        "outputId": "ee2b551a-05ed-4a0c-d716-68fd570ca964"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy results:\n",
            "     Sampling1   Sampling2   Sampling3   Sampling4   Sampling5\n",
            "M1  100.000000  100.000000  100.000000  100.000000  100.000000\n",
            "M2   74.368231   71.774194   70.476190   71.038251   70.860927\n",
            "M3   92.779783   89.919355   89.523810   92.896175   93.377483\n",
            "M4   99.277978   97.983871   96.666667   97.814208   94.039735\n",
            "M5  100.000000   99.596774  100.000000   99.453552   98.013245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the results in a file\n",
        "result_df.to_csv(\"results.csv\", index=True)"
      ],
      "metadata": {
        "id": "p0PA0lm6Vpnf"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}